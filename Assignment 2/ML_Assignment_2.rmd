---
title: "ASSIGNMENT_2_64060"
author: "Rohith Desamseety"
date: "2022-10-06"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup}

#importing the necessary packages
library('caret')
library('ISLR')
library('dplyr')
library('class')

#Importing the dataset
rundata <- read.csv("~/Downloads/UniversalBank.csv", header = TRUE, 
                         sep =",", stringsAsFactors = FALSE)
#Question_1
#performing a k-NN classification with all predictors deleted, deleting ID and ZIP Code from every single column
rundata$ID <- NULL
rundata$ZIP.Code <- NULL
summary(rundata)

#translating the categorical variable "personal loan" into a variable that distinguishes between "yes" and "no" responses.

rundata$Personal.Loan=  as.factor(rundata$Personal.Loan)


#Apply preProcess() from the caret package to divide the data into training and validation in order to standardize it.
M_norm <- preProcess(rundata[, -8],method = c("center", "scale"))
rundata_norm <- predict(M_norm,rundata)
summary(rundata_norm)


#separating the data into test and training sets
T_index <- createDataPartition(rundata$Personal.Loan, p = 0.6, list = FALSE)
t.df = rundata_norm[T_index,]
validate.df = rundata_norm[-T_index,]

print(head(t.df))

#predictions of data
library(caret)
library(FNN)

my.predict = data.frame(Age = 40, Experience = 10, Income = 84, Family = 2,
                        CCAvg = 2, Education = 1, Mortgage = 0, Securities.Account =
                          0, CD.Account = 0, Online = 1, CreditCard = 1)
print(my.predict)
my.predict_Norm <- predict(M_norm,my.predict)

predictions <- knn(train= as.data.frame(t.df[,1:7,9:12]),
                  test = as.data.frame(my.predict_Norm[,1:7,9:12]),
                  cl= t.df$Personal.Loan,
                  k=1)
print(predictions)

```
```{r}
#Question_2 
#finding the K value that strikes a compromise between over- and underfitting.
set.seed(123)
UniBank <- trainControl(method= "repeatedcv", number = 3, repeats = 2)
searchGrid = expand.grid(k=1:10)

knn.model = train(Personal.Loan~., data = t.df, method = 'knn', tuneGrid = searchGrid,trControl = UniBank)

knn.model
```
```{r}
#The best value of k is 3, which finds a balance between underfitting and overfitting of the data.
#Question 3
#confusion Matrix is below
pre_bank <- predict(knn.model,validate.df)

confusionMatrix(pre_bank,validate.df$Personal.Loan)
#The matrix's accuracy rate is 95.1%.
```
```{r}
#Question 4
#Levels
#utilizing the highest K to categorize the customer.
my.predict_Norm = data.frame(Age = 40, Experience = 10, Income = 84, Family = 2,
                                   CCAvg = 2, Education = 1, Mortgage = 0,
                                   Securities.Account =0, CD.Account = 0, Online = 1,
                                   CreditCard = 1)
my.predict_Norm = predict(M_norm, my.predict)
predict(knn.model, my.predict_Norm)
#There is also a plot that displays the optimal K (3) value, which is the one with the greatest accuracy.
plot(knn.model, type = "b", xlab = "K-Value", ylab = "Accuracy")
```

```{r}
#Question 5
#constructing training, test, and validation sets using the data that was collected.
train_size = 0.5 #training(50%)
T_index = createDataPartition(rundata$Personal.Loan, p = 0.5, list = FALSE)
t.df = rundata_norm[T_index,]


test_size = 0.2 #Test Data(20%)
Test_index = createDataPartition(rundata$Personal.Loan, p = 0.2, list = FALSE)
Test.df = rundata_norm[Test_index,]


valid_size = 0.3 #validation(30%)
Validation_index = createDataPartition(rundata$Personal.Loan, p = 0.3, list = FALSE)
validate.df = rundata_norm[Validation_index,]



Testingsknn <- knn(train = t.df[,-8], test = Test.df[,-8], cl = t.df[,8], k =3)
validateknn <- knn(train = t.df[,-8], test = validate.df[,-8], cl = t.df[,8], k =3)
Trainsknn <- knn(train = t.df[,-8], test = t.df[,-8], cl = t.df[,8], k =3)

confusionMatrix(Testingsknn, Test.df[,8])
confusionMatrix(validateknn, validate.df[,8])
confusionMatrix(Trainsknn, t.df[,8])

#Final Conclusion: The training data had improved accuracy and sensitivity. 
#The above matrices were used to determine the values for the Test, Training, and Validation sets, which are 96.3%, 97.32%, and 96.73%, respectively.
#If the Training data were more accurate than the other sets, it might be considered that overfitting would take place. When comparing the accuracy of the Training, Test, and Validation sets to the testing data and the validation data, we can say that we have found the highest value of k.



```
